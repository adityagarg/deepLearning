{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECBM4040 Assignment 1, Task 4: Questions\n",
    "\n",
    "1) What is the difference between the SVM method and a neural network, assuming that both work with the same number of training samples N?\n",
    "\n",
    "   Your answer: **SVM tries to find a hyperplane that attempts to classify points by maximizing the margin width between cluster of points, while a neural network tries to approximate a distribution function that can minimize the loss and thus, classify points correctly.\n",
    "   SVM's advantage is that it is less prone to overfitting and don't get stuck in a local minima, while Neural Network have the advantage of learning features from almost any kind of data without having to explicitly define them manually.**\n",
    "   \n",
    "\n",
    "\n",
    "2) Why is the ReLU activation function used the most often in neural networks for computer vision?\n",
    "\n",
    "   Your answer: **Rectified Linear Unit (ReLU) is used in neural networks for its computationally less expensive nature and its simple constant gradient computation that does not suffer from vanishing gradient problem and allows faster learning. Another advantage of ReLU is its sparsity since it generates 0 value for negative elements.**\n",
    "   \n",
    "\n",
    "3) Describe your best model in the implementation of the two-layer neural network. Describe your starting point, how you tuned  the hyperparameters, which stategies you did you use to improve the network, show the results of intermediate and final steps.\n",
    "\n",
    "   Your answer: **My best model in the two-layer neural network is structured as below:\n",
    "   Input->(Affine->ReLU)->(Affine->Softmax)->Output \n",
    "   To optimize my model, I adjusted the parameteres such that they gave the highest validation and test accuracy. To tune the hyperparameters, I adjusted the value of one hyperparameter at a time while keeping the rest constant. I kept increasing or decreasing the value of the hyperparameter in the direction they improved the accuracy in till they reached a saturation point. Reducing the batch size and increasing the hidden layer dimensions have the best results. <br><u>Results of intermediate and final steps (Params : test_accuracy):</u>\n",
    "   <br>Intermediate:\n",
    "    <br> hidden_dim=100, reg=0.25, weight_scale=1e-3, batch_size = 500, lr = 1e-3 : 0.4861\n",
    "   <br>Final:\n",
    "    <br> hidden_dim=150,  reg=0.5, weight_scale=1e-3, batch_size = 100, lr = 1.5e-3 : 0.5017\n",
    "    **\n",
    "   \n",
    "\n",
    "4) **Cross validation** is a technique used to prove the generalization ability of a model and can help you find a robust set of hyperparameters. Please describe the implementation details of **k-fold cross validation** if you want to use it to find a best set of hyperparameter of the **Linear SVM classification** problem.\n",
    "\n",
    "   Your answer: **In k-fold cross validation, the data set is divided into k equal folds i.e. k subsamples of equal size. The model is then trained on k-1 subsamples and tested on the left-out(validation) subsample. This cross validation is repeated k times, such that each subsample is used as validation data exactly once. The k results are then averaged to produce a single estimated error (or some function) value. K-fold validation is used in hyperparameter tuning by varying the values of hyperparameters and picking the set of hyperparameters that give the best estimated average value in k-fold cross validation process.  **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dlWorks]",
   "language": "python",
   "name": "conda-env-dlWorks-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
