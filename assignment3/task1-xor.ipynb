{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy.random import shuffle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot configurations\n",
    "% matplotlib inline\n",
    "\n",
    "# Notebook auto reloads code. (Ref: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython)\n",
    "% load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1, Part 1: Backpropagation through time (BPTT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Consider a simple RNN network shown in the following figure, where __ _wi, wh, b, a, c_ __ are the scalar parameters of the network. The loss function is the **mean squared error (MSE)**. Given input (x0, x1) = (1, 0), ground truth (g1, g2) = (1, 1), h0 = 0, (wi, wh, b, a, c) = (1, 1, 1, 1, 1), compute __ _(dwi, dwh, db, da, dc)_ __, which are the gradients of loss with repect to 5 parameters __ _(wi, wh, b, a, c)_ __.\n",
    "\n",
    "![bptt](./img/bptt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">TODO:</span>\n",
    "\n",
    "Answer the above question. \n",
    "\n",
    "* **[fill in here: Enter your derivations and the computational process]**\n",
    "* You can use LATEX to edit the equations, and Jupyter notebook can recognize basic LATEX syntax. Alternatively, you can edit equations in some other environment and then paste the screenshot of the equations here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1, Part 2: Use tensorflow modules to create XOR network\n",
    "\n",
    "In this part, you need to build and train an XOR network that can learn the XOR function. It is a very simple implementation of RNN and will give you an idea how RNN is built and how to train it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR network\n",
    "\n",
    "XOR network can learn the XOR $\\oplus$ function\n",
    "\n",
    "As shown in the figure below, and for instance, if input $(x0, x1, x2)$=(1,0,0), then output $(y1, y2, y3)$=(1,1,1). That is, $y_n = x_0\\oplus x_1 \\oplus ... \\oplus x_{n-1}$\n",
    "\n",
    "![xor_net](./img/xor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data set\n",
    "This function provides you the way to generate the data which is required for the training process. You should utilize it when building your training function for the LSTM. Please read the source code for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ecbm4040.xor.utils import create_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a network using a Tensorlow LSTMCell\n",
    "This section shows an example how to build a RNN network using an LSTM cell. LSTM cell is an inbuilt class in tensorflow which implements the real behavior of the LSTM neuron. \n",
    "\n",
    "Reference: [TensorFlow LSTM cell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/LSTMCell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.rnn import LSTMCell\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Input shape: (num_samples, seq_length, input_dimension)\n",
    "# Output shape: (num_samples, output_ground_truth), and output_ground_truth is 0/1. \n",
    "input_data = tf.placeholder(tf.float32,shape=[None,None,1])\n",
    "output_data = tf.placeholder(tf.int64,shape=[None,None])\n",
    "\n",
    "# define LSTM cell\n",
    "lstm_units = 64\n",
    "cell = LSTMCell(lstm_units,num_proj=2,state_is_tuple=True)\n",
    "\n",
    "# create LSTM network: you can also choose other modules provided by tensorflow, like static_rnn etc.\n",
    "out,_ = tf.nn.dynamic_rnn(cell,input_data,dtype=tf.float32)\n",
    "pred = tf.argmax(out,axis=2)\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=output_data,logits=out))\n",
    "\n",
    "# optimization\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss)\n",
    "\n",
    "# accuracy\n",
    "correct_num = tf.equal(output_data,pred)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_num,tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training \n",
    "\n",
    "<span style='color:red'>TODO:</span> \n",
    "1. Build your training funciton for RNN; \n",
    "2. Plot the cost during the traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (80, 8, 1)\n",
      "Train labels shape:  (80, 8)\n",
      "Validation data shape:  (20, 8, 1)\n",
      "Validation labels shape:  (20, 8)\n"
     ]
    }
   ],
   "source": [
    "#Create Data\n",
    "\n",
    "#Create dataset\n",
    "num_samples=100\n",
    "fraction_validation=0.2\n",
    "X_train, y_train = create_dataset(num_samples)\n",
    "\n",
    "# Data organizations:\n",
    "\n",
    "num_validation = int(fraction_validation*num_samples)\n",
    "\n",
    "X_val = X_train[-num_validation:, :, :]\n",
    "y_val = y_train[-num_validation:, :]\n",
    "\n",
    "X_train = X_train[:-num_validation, :, :]\n",
    "y_train = y_train[:-num_validation, :]\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of batches for training: 16\n",
      "epoch 1 \n",
      "5/80 loss: 0.6941953897476196\n",
      "10/80 loss: 0.8495915532112122\n",
      "15/80 loss: 0.6931100487709045\n",
      "20/80 loss: 0.6944262385368347\n",
      "25/80 loss: 0.6917951107025146\n",
      "30/80 loss: 0.6796250343322754\n",
      "35/80 loss: 0.63965904712677\n",
      "40/80 loss: 0.7177687883377075\n",
      "45/80 loss: 0.6189892292022705\n",
      "50/80 loss: 0.6636059880256653\n",
      "55/80 loss: 0.7714413404464722\n",
      "60/80 loss: 0.7221395373344421\n",
      "65/80 loss: 0.6739863157272339\n",
      "70/80 loss: 0.6852643489837646\n",
      "75/80 loss: 0.672961413860321\n",
      "80/80 loss: 0.6915510296821594\n",
      "epoch 2 \n",
      "5/80 loss: 0.6815937757492065\n",
      "10/80 loss: 0.6616198420524597\n",
      "15/80 loss: 0.6795204281806946\n",
      "20/80 loss: 0.7202610969543457\n",
      "25/80 loss: 0.7321807146072388\n",
      "30/80 loss: 0.6548932194709778\n",
      "35/80 loss: 0.5797474980354309\n",
      "40/80 loss: 0.6449407935142517\n",
      "45/80 loss: 0.6097747087478638\n",
      "50/80 loss: 0.576815128326416\n",
      "55/80 loss: 0.7297480702400208\n",
      "60/80 loss: 0.5665927529335022\n",
      "65/80 loss: 0.6809547543525696\n",
      "70/80 loss: 0.7391417622566223\n",
      "75/80 loss: 0.6811830401420593\n",
      "80/80 loss: 0.5908433198928833\n",
      "epoch 3 \n",
      "5/80 loss: 0.6304981112480164\n",
      "10/80 loss: 0.6217890977859497\n",
      "15/80 loss: 0.6582169532775879\n",
      "20/80 loss: 0.6769925951957703\n",
      "25/80 loss: 0.6943126916885376\n",
      "30/80 loss: 0.6139135360717773\n",
      "35/80 loss: 0.5998262166976929\n",
      "40/80 loss: 0.6135179400444031\n",
      "45/80 loss: 0.5561733841896057\n",
      "50/80 loss: 0.5699650049209595\n",
      "55/80 loss: 0.6708742380142212\n",
      "60/80 loss: 0.59706050157547\n",
      "65/80 loss: 0.587766170501709\n",
      "70/80 loss: 0.5857511758804321\n",
      "75/80 loss: 0.5108269453048706\n",
      "80/80 loss: 0.5496954321861267\n",
      "epoch 4 \n",
      "5/80 loss: 0.5104557871818542\n",
      "10/80 loss: 0.4712292551994324\n",
      "15/80 loss: 0.3807258605957031\n",
      "20/80 loss: 0.3578866422176361\n",
      "25/80 loss: 0.23214474320411682\n",
      "30/80 loss: 0.19860048592090607\n",
      "35/80 loss: 0.11733486503362656\n",
      "40/80 loss: 0.12669813632965088\n",
      "45/80 loss: 0.08689923584461212\n",
      "50/80 loss: 0.03972043842077255\n",
      "55/80 loss: 0.03898129612207413\n",
      "60/80 loss: 0.02726704441010952\n",
      "65/80 loss: 0.02945840358734131\n",
      "70/80 loss: 0.01627338118851185\n",
      "75/80 loss: 0.007469101343303919\n",
      "80/80 loss: 0.0056340740993618965\n",
      "epoch 5 \n",
      "5/80 loss: 0.0072776242159307\n",
      "10/80 loss: 0.004549794364720583\n",
      "15/80 loss: 0.0063186450861394405\n",
      "20/80 loss: 0.004332768730819225\n",
      "25/80 loss: 0.003562137484550476\n",
      "30/80 loss: 0.0019193984335288405\n",
      "35/80 loss: 0.0017426032572984695\n",
      "40/80 loss: 0.001425432157702744\n",
      "45/80 loss: 0.001426671864464879\n",
      "50/80 loss: 0.00097877427469939\n",
      "55/80 loss: 0.0022856153082102537\n",
      "60/80 loss: 0.0007926753023639321\n",
      "65/80 loss: 0.0010623835260048509\n",
      "70/80 loss: 0.000753730651922524\n",
      "75/80 loss: 0.0010457707103341818\n",
      "80/80 loss: 0.0007897359319031239\n",
      "epoch 6 \n",
      "5/80 loss: 0.0008474431815557182\n",
      "10/80 loss: 0.0005591116496361792\n",
      "15/80 loss: 0.0008356316247954965\n",
      "20/80 loss: 0.0006094014970585704\n",
      "25/80 loss: 0.0006369603797793388\n",
      "30/80 loss: 0.0004315685946494341\n",
      "35/80 loss: 0.000428133353125304\n",
      "40/80 loss: 0.0004713290254585445\n",
      "45/80 loss: 0.0004992372123524547\n",
      "50/80 loss: 0.00031974585726857185\n",
      "55/80 loss: 0.0007858859607949853\n",
      "60/80 loss: 0.0003795493976213038\n",
      "65/80 loss: 0.00043728359742090106\n",
      "70/80 loss: 0.00029422942316159606\n",
      "75/80 loss: 0.0003758642706088722\n",
      "80/80 loss: 0.0002808179415296763\n",
      "epoch 7 \n",
      "5/80 loss: 0.00037228420842438936\n",
      "10/80 loss: 0.00024664952070452273\n",
      "15/80 loss: 0.0004117267089895904\n",
      "20/80 loss: 0.000311827112454921\n",
      "25/80 loss: 0.0003320039249956608\n",
      "30/80 loss: 0.00027059734566137195\n",
      "35/80 loss: 0.00029728852678090334\n",
      "40/80 loss: 0.00027880852576345205\n",
      "45/80 loss: 0.00026598788099363446\n",
      "50/80 loss: 0.00017956520605366677\n",
      "55/80 loss: 0.00023448580759577453\n",
      "60/80 loss: 0.00017489984747953713\n",
      "65/80 loss: 0.00022882726625539362\n",
      "70/80 loss: 0.00017468347505200654\n",
      "75/80 loss: 0.00023655840777792037\n",
      "80/80 loss: 0.0001608042512089014\n",
      "epoch 8 \n",
      "5/80 loss: 0.00027171606780029833\n",
      "10/80 loss: 0.00018783877021633089\n",
      "15/80 loss: 0.0002584287722129375\n",
      "20/80 loss: 0.00018026144243776798\n",
      "25/80 loss: 0.00020954357751179487\n",
      "30/80 loss: 0.00013732947991229594\n",
      "35/80 loss: 0.0001359903544653207\n",
      "40/80 loss: 0.00015405511658173054\n",
      "45/80 loss: 0.00015143254131544381\n",
      "50/80 loss: 0.00011487617302918807\n",
      "55/80 loss: 0.00018710528092924505\n",
      "60/80 loss: 0.00013016126467846334\n",
      "65/80 loss: 0.00017208914505317807\n",
      "70/80 loss: 0.000129867039504461\n",
      "75/80 loss: 0.00017852084420155734\n",
      "80/80 loss: 0.00012200009223306552\n",
      "epoch 9 \n",
      "5/80 loss: 0.00019853706180583686\n",
      "10/80 loss: 0.0001393864513374865\n",
      "15/80 loss: 0.00018687773263081908\n",
      "20/80 loss: 0.0001342649047728628\n",
      "25/80 loss: 0.00016134518955368549\n",
      "30/80 loss: 0.00011509629257488996\n",
      "35/80 loss: 0.00011296230513835326\n",
      "40/80 loss: 0.00012021847942378372\n",
      "45/80 loss: 0.00012726560817100108\n",
      "50/80 loss: 9.719348599901423e-05\n",
      "55/80 loss: 0.0001398471649736166\n",
      "60/80 loss: 0.0001081181108020246\n",
      "65/80 loss: 0.00013537859194912016\n",
      "70/80 loss: 0.0001067956181941554\n",
      "75/80 loss: 0.00014363927766680717\n",
      "80/80 loss: 0.00010231979831587523\n",
      "epoch 10 \n",
      "5/80 loss: 0.00015848633483983576\n",
      "10/80 loss: 0.00011598008859436959\n",
      "15/80 loss: 0.0001521243539173156\n",
      "20/80 loss: 0.0001115106642828323\n",
      "25/80 loss: 0.00013479024346452206\n",
      "30/80 loss: 9.703393880045041e-05\n",
      "35/80 loss: 9.398219845024869e-05\n",
      "40/80 loss: 9.916177805280313e-05\n",
      "45/80 loss: 0.00010695385572034866\n",
      "50/80 loss: 7.98332184785977e-05\n",
      "55/80 loss: 0.00012179881014162675\n",
      "60/80 loss: 8.922998677007854e-05\n",
      "65/80 loss: 0.00011403369717299938\n",
      "70/80 loss: 8.744838123675436e-05\n",
      "75/80 loss: 0.00012321215763222426\n",
      "80/80 loss: 8.494807843817398e-05\n",
      "epoch 11 \n",
      "5/80 loss: 0.0001369692909065634\n",
      "10/80 loss: 0.00010356168786529452\n",
      "15/80 loss: 0.00012955523561686277\n",
      "20/80 loss: 9.575158037478104e-05\n",
      "25/80 loss: 0.00011609985085669905\n",
      "30/80 loss: 8.305006485898048e-05\n",
      "35/80 loss: 8.068670285865664e-05\n",
      "40/80 loss: 8.511533087585121e-05\n",
      "45/80 loss: 9.28807639866136e-05\n",
      "50/80 loss: 6.875388498883694e-05\n",
      "55/80 loss: 0.00010515221219975501\n",
      "60/80 loss: 7.679833652218804e-05\n",
      "65/80 loss: 9.856389078777283e-05\n",
      "70/80 loss: 7.538311183452606e-05\n",
      "75/80 loss: 0.00010725070023909211\n",
      "80/80 loss: 7.400030881399289e-05\n",
      "epoch 12 \n",
      "5/80 loss: 0.00011762008216464892\n",
      "10/80 loss: 8.909236930776387e-05\n",
      "15/80 loss: 0.00011217266001040116\n",
      "20/80 loss: 8.368092676391825e-05\n",
      "25/80 loss: 0.00010188730811933056\n",
      "30/80 loss: 7.359513256233186e-05\n",
      "35/80 loss: 7.191724580479786e-05\n",
      "40/80 loss: 7.4739582487382e-05\n",
      "45/80 loss: 8.261246694019064e-05\n",
      "50/80 loss: 6.092548574088141e-05\n",
      "55/80 loss: 9.09094960661605e-05\n",
      "60/80 loss: 6.77098214509897e-05\n",
      "65/80 loss: 8.682418410899118e-05\n",
      "70/80 loss: 6.65984844090417e-05\n",
      "75/80 loss: 9.472430974710733e-05\n",
      "80/80 loss: 6.552560807904229e-05\n",
      "epoch 13 \n",
      "5/80 loss: 0.00010308845958206803\n",
      "10/80 loss: 7.828185334801674e-05\n",
      "15/80 loss: 9.89134277915582e-05\n",
      "20/80 loss: 7.411893602693453e-05\n",
      "25/80 loss: 9.05109554878436e-05\n",
      "30/80 loss: 6.562700582435355e-05\n",
      "35/80 loss: 6.420245335903019e-05\n",
      "40/80 loss: 6.658070924459025e-05\n",
      "45/80 loss: 7.38339003873989e-05\n",
      "50/80 loss: 5.4640659072902054e-05\n",
      "55/80 loss: 8.056398655753583e-05\n",
      "60/80 loss: 6.0674326959997416e-05\n",
      "65/80 loss: 7.77212408138439e-05\n",
      "70/80 loss: 5.977749970043078e-05\n",
      "75/80 loss: 8.476911170873791e-05\n",
      "80/80 loss: 5.8683781389845535e-05\n",
      "epoch 14 \n",
      "5/80 loss: 9.198019688483328e-05\n",
      "10/80 loss: 6.99890879332088e-05\n",
      "15/80 loss: 8.838924259180203e-05\n",
      "20/80 loss: 6.648768612649292e-05\n",
      "25/80 loss: 8.127976616378874e-05\n",
      "30/80 loss: 5.917552698520012e-05\n",
      "35/80 loss: 5.7917881349567324e-05\n",
      "40/80 loss: 6.004876922816038e-05\n",
      "45/80 loss: 6.672391464235261e-05\n",
      "50/80 loss: 4.968189023202285e-05\n",
      "55/80 loss: 7.21372343832627e-05\n",
      "60/80 loss: 5.515852171811275e-05\n",
      "65/80 loss: 7.036427268758416e-05\n",
      "70/80 loss: 5.4452371841762215e-05\n",
      "75/80 loss: 7.662244752282277e-05\n",
      "80/80 loss: 5.3293100791051984e-05\n",
      "epoch 15 \n",
      "5/80 loss: 8.277279994217679e-05\n",
      "10/80 loss: 6.310267053777352e-05\n",
      "15/80 loss: 7.973611354827881e-05\n",
      "20/80 loss: 6.026875780662522e-05\n",
      "25/80 loss: 7.36813381081447e-05\n",
      "30/80 loss: 5.40023684152402e-05\n",
      "35/80 loss: 5.280731784296222e-05\n",
      "40/80 loss: 5.4708718380425125e-05\n",
      "45/80 loss: 6.088626105338335e-05\n",
      "50/80 loss: 4.5587301428895444e-05\n",
      "55/80 loss: 6.522706098621711e-05\n",
      "60/80 loss: 5.054556459072046e-05\n",
      "65/80 loss: 6.426166510209441e-05\n",
      "70/80 loss: 5.003011756343767e-05\n",
      "75/80 loss: 6.984635547269136e-05\n",
      "80/80 loss: 4.881423228653148e-05\n",
      "epoch 16 \n",
      "5/80 loss: 7.51713669160381e-05\n",
      "10/80 loss: 5.7479639508528635e-05\n",
      "15/80 loss: 7.256378012243658e-05\n",
      "20/80 loss: 5.508079266292043e-05\n",
      "25/80 loss: 6.734325143042952e-05\n",
      "30/80 loss: 4.960990554536693e-05\n",
      "35/80 loss: 4.8510228225495666e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/80 loss: 5.020599201088771e-05\n",
      "45/80 loss: 5.598127609118819e-05\n",
      "50/80 loss: 4.209169128444046e-05\n",
      "55/80 loss: 5.9529604186536744e-05\n",
      "60/80 loss: 4.663585059461184e-05\n",
      "65/80 loss: 5.9103582316311076e-05\n",
      "70/80 loss: 4.625150540960021e-05\n",
      "75/80 loss: 6.414293602574617e-05\n",
      "80/80 loss: 4.502667434280738e-05\n",
      "epoch 17 \n",
      "5/80 loss: 6.877963460283354e-05\n",
      "10/80 loss: 5.2735624194610864e-05\n",
      "15/80 loss: 6.648792623309419e-05\n",
      "20/80 loss: 5.071224950370379e-05\n",
      "25/80 loss: 6.194672459969297e-05\n",
      "30/80 loss: 4.589684976963326e-05\n",
      "35/80 loss: 4.4832944695372134e-05\n",
      "40/80 loss: 4.637372330762446e-05\n",
      "45/80 loss: 5.1773553423117846e-05\n",
      "50/80 loss: 3.9072871004464105e-05\n",
      "55/80 loss: 5.471113763633184e-05\n",
      "60/80 loss: 4.324163819546811e-05\n",
      "65/80 loss: 5.467252412927337e-05\n",
      "70/80 loss: 4.299436477595009e-05\n",
      "75/80 loss: 5.921419869991951e-05\n",
      "80/80 loss: 4.178145172772929e-05\n",
      "epoch 18 \n",
      "5/80 loss: 6.327582377707586e-05\n",
      "10/80 loss: 4.8670983233023435e-05\n",
      "15/80 loss: 6.12761577940546e-05\n",
      "20/80 loss: 4.693070877692662e-05\n",
      "25/80 loss: 5.730702469008975e-05\n",
      "30/80 loss: 4.2666521039791405e-05\n",
      "35/80 loss: 4.1647326725069433e-05\n",
      "40/80 loss: 4.304206959204748e-05\n",
      "45/80 loss: 4.8126039473572746e-05\n",
      "50/80 loss: 3.6468270991463214e-05\n",
      "55/80 loss: 5.0539274525363e-05\n",
      "60/80 loss: 4.028248804388568e-05\n",
      "65/80 loss: 5.081950803287327e-05\n",
      "70/80 loss: 4.015142621938139e-05\n",
      "75/80 loss: 5.4940999689279124e-05\n",
      "80/80 loss: 3.892361564794555e-05\n",
      "epoch 19 \n",
      "5/80 loss: 5.8490106312092394e-05\n",
      "10/80 loss: 4.514569081948139e-05\n",
      "15/80 loss: 5.675865031662397e-05\n",
      "20/80 loss: 4.365274799056351e-05\n",
      "25/80 loss: 5.3236457461025566e-05\n",
      "30/80 loss: 3.98235788452439e-05\n",
      "35/80 loss: 3.8858026528032497e-05\n",
      "40/80 loss: 4.012164208688773e-05\n",
      "45/80 loss: 4.493742744671181e-05\n",
      "50/80 loss: 3.413485683267936e-05\n",
      "55/80 loss: 4.693950904766098e-05\n",
      "60/80 loss: 3.7663041439373046e-05\n",
      "65/80 loss: 4.7416429879376665e-05\n",
      "70/80 loss: 3.7636273191310465e-05\n",
      "75/80 loss: 5.11713806190528e-05\n",
      "80/80 loss: 3.6411442124517635e-05\n",
      "epoch 20 \n",
      "5/80 loss: 5.431522731669247e-05\n",
      "10/80 loss: 4.204054130241275e-05\n",
      "15/80 loss: 5.279236938804388e-05\n",
      "20/80 loss: 4.071745934197679e-05\n",
      "25/80 loss: 4.965753760188818e-05\n",
      "30/80 loss: 3.7317367969080806e-05\n",
      "35/80 loss: 3.636969631770626e-05\n",
      "40/80 loss: 3.754986391868442e-05\n",
      "45/80 loss: 4.2064675653818995e-05\n",
      "50/80 loss: 3.206069959560409e-05\n",
      "55/80 loss: 4.375393473310396e-05\n",
      "60/80 loss: 3.5326684155734256e-05\n",
      "65/80 loss: 4.44126344518736e-05\n",
      "70/80 loss: 3.5368451790418476e-05\n",
      "75/80 loss: 4.7818921302678064e-05\n",
      "80/80 loss: 3.418534106458537e-05\n",
      "Traning ends.\n"
     ]
    }
   ],
   "source": [
    "epoch=20\n",
    "batch_size=5\n",
    "\n",
    "iters = int(X_train.shape[0] / batch_size)\n",
    "print('number of batches for training: {}'.format(iters))\n",
    "\n",
    "iter_total = 0\n",
    "best_acc = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epc in range(epoch):\n",
    "        print(\"epoch {} \".format(epc + 1))\n",
    "\n",
    "        for itr in range(iters):\n",
    "\n",
    "            training_batch_x = X_train[itr * batch_size: (1 + itr) * batch_size]\n",
    "            training_batch_y = y_train[itr * batch_size: (1 + itr) * batch_size]\n",
    "\n",
    "            _, cur_loss = sess.run([optimizer, loss], feed_dict={input_data: training_batch_x, output_data: training_batch_y})\n",
    "            print('{}/{} loss: {}'.format(\n",
    "                    batch_size * (itr + 1),\n",
    "                    X_train.shape[0],\n",
    "                    cur_loss))\n",
    "print(\"Traning ends.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task 1, Part 3 :  Build your own LSTMCell\n",
    "In this part, you need to build your own LSTM cell to achieve the LSTM functionality. \n",
    "\n",
    "<span style=\"color:red\">TODO:</span> \n",
    "1. Finish class **MyLSTMCell** in ecbm4040/xor/rnn.py;\n",
    "2. Write the training function for your RNN;\n",
    "3. Plot the cost during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ecbm4040.xor.rnn import MyLSTMCell\n",
    "\n",
    "# recreate xor netowrk with your own LSTM cell\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#Input shape: (num_samples,seq_length,input_dimension)\n",
    "#Output shape: (num_samples, output_ground_truth), and output_ground_truth is 0/1. \n",
    "input_data = tf.placeholder(tf.float32,shape=[None,None,1])\n",
    "output_data = tf.placeholder(tf.int64,shape=[None,None])\n",
    "\n",
    "# recreate xor netowrk with your own LSTM cell\n",
    "lstm_units = 64\n",
    "cell = MyLSTMCell(lstm_units,num_proj=2)\n",
    "\n",
    "# create LSTM network: you can also choose other modules provided by tensorflow, like static_rnn etc.\n",
    "out,_ = tf.nn.dynamic_rnn(cell,input_data,dtype=tf.float32)\n",
    "pred = tf.argmax(out,axis=2)\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=output_data,logits=out))\n",
    "# optimization\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss)\n",
    "# accuracy\n",
    "correct = tf.equal(output_data,pred)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR TRAINING AND PLOTTING CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zoran\\Anaconda3\\envs\\dlWorksA3\\lib\\site-packages\\tensorflow\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print (tf.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ADI/anaconda/envs/dlWorks/lib/python3.5/site-packages/tensorflow/__init__.py\n"
     ]
    }
   ],
   "source": [
    "print(tf.__file__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (dlWorks)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
